{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526d4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060b7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"F:/simplilearn/Analytics vidya/train_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698e865e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is good in a decision tree, a large or a ...</td>\n",
       "      <td>Techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Training data only contains single positive label</td>\n",
       "      <td>Techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Calculating percentage contribution of a negat...</td>\n",
       "      <td>Techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Unable to open solution checker!</td>\n",
       "      <td>Hackathons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User Name Change</td>\n",
       "      <td>Misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              Title      Domain\n",
       "0   1  What is good in a decision tree, a large or a ...  Techniques\n",
       "1   2  Training data only contains single positive label  Techniques\n",
       "2   3  Calculating percentage contribution of a negat...  Techniques\n",
       "3   4                   Unable to open solution checker!  Hackathons\n",
       "4   5                                   User Name Change        Misc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45dc95e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Integer Optimization with weighted / priority approaches   :-   Techniques \n",
      "\n",
      "Gradient Boosting Classifier in Python - Unable to run   :-   Techniques \n",
      "\n",
      "Career switch from mechanical engineer role to analytics   :-   Techniques \n",
      "\n",
      "How to Cluster graphs   :-   Hackathons \n",
      "\n",
      "What should I consider while adding or deleting features?   :-   Misc \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# viewing some texts from the dataframe\n",
    "\n",
    "for i in range(5):\n",
    "    print(df.sample(frac=1).iloc[i,1],'  :-  ' , df.iloc[i,2] ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e39da39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID         0\n",
       "Title     11\n",
       "Domain     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f785da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset='Title',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bccfdd3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3834, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477f41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  some texts have \"?\"mark or may be other non alphanumeric character attached with swords like \"error?\" .\n",
    "# so that NLP gets clear words for text processing and balcncing dataset with synonyms\n",
    "# we are using NLPAUG for balancing dataset , so NLPAUG may not understand \"error?\" , so we replace it with \"error ?\"\n",
    "# just adding a space between the word and \"?\"mark\n",
    "\n",
    "import re\n",
    "\n",
    "def add_space(text):\n",
    "    pattern = r\"(\\w+)\\s*(\\W)\"\n",
    "\n",
    "    # Replace the matched pattern with a space between the two groups\n",
    "    replaced_text = re.sub(pattern, r\"\\1 \", text)\n",
    "\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f098e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].apply(lambda x : add_space(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cda0e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3834, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2054f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Domain\n",
       "Techniques    1852\n",
       "Tools          917\n",
       "Career         437\n",
       "Hackathons     262\n",
       "Resources      170\n",
       "Other          122\n",
       "Misc            74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20dba811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding the target cloumn which has 7 classes\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df['Domain'] = LabelEncoder().fit_transform(df['Domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c57d5",
   "metadata": {},
   "source": [
    "### we have many echniques to balanced text dataset . \n",
    "### firstly , translating the sentence to other language and then back trnslating it to english . the problem with this is the final translation is exactly same as the orignal sentence , so this is not found useful.\n",
    "### secondly , replacing some words in the sentence with other worsds based on the context of the sentence . but this didnt give good accuracy.\n",
    "### third , replace the words in sentence with their synonyms . this  is found good for this problem . as the accuracies were good on both training and test dataset . so i used this . this is done using NLPAUG library\n",
    "### also thereare other techniques like adding random letters or words to the sentence but that is found not good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291a39e",
   "metadata": {},
   "source": [
    "# synonym AUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53062ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "from tqdm.auto import tqdm # used to know the status of execution\n",
    "import multiprocessing  #this library is used to include all cores in the process,so that it is done fast .same as n_jobs = -1\n",
    "import time  # this is just to note the total time taken for the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96030e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = naw.SynonymAug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "843bf5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which algorithm to choose when the response is weak  \n",
      "\n",
      "['Which algorithm to choose when the reaction is feeble']\n"
     ]
    }
   ],
   "source": [
    "print(df.Title[9],'\\n')\n",
    "print(augmenter.augment(df.Title[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3da38ef",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9b993ad0d946f18fa874b9c07679fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077692d49a1f4667af732e1db518e118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d5672740ca454d85a36507c2ab7a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb9b88aefec48e2aabe0bc3c5788237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614ed0893874412baf44ead1ba01f11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87045c404784b408aba14022fb1021e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time taken to complete is :  0.7961856087048849  minutes .\n"
     ]
    }
   ],
   "source": [
    "# created these to append the  newly generated sentences and later we can create a new balanced data frame with these list\n",
    "texts_ , labels_ = [],[]\n",
    "\n",
    "# sometimes this process interrupts , just re-run this cell . sometimes you need to re-run this twice or thrice\n",
    "\n",
    "time.sleep(1) # adding the timegap of 1 second\n",
    "start_ = time.time() # noting the start time\n",
    "\n",
    "# from line 11 to last in this cell .\n",
    "# line 27 :  , considering the length of unique classes in target variable.\n",
    "# the highest vallue counts are for class are for \"Techniques\" 1852  total ,so we are not considering the texts of\n",
    "# that class , as we are bringing value counts of other class to \"techniques\" 1852 .\n",
    "# so we are not  generating new sentences for \"techniques\"\n",
    "# line 28 : we have value counts for class \"tools\" = 917 . so we are doing ( 1852 - 917 ) // 917 ,\n",
    "# now we have an INT value for how many number of new texts we want to generate for class \"tools\" ,\n",
    "# if the value is 2 then  we generate 2 new sentences for each sentence of class \"tools\" .\n",
    "# to make its value count closer or equal to counts of \"techniques\" . same with other classes .\n",
    "# line 29 : we are just printing what is the ( 1852 - 917 ) // 917 value for each class\n",
    "# line 31 : consindering the range one particular class (example range oftotal number of texts belonging to class \"tools\")\n",
    "# line 32 : calling every text in it using for loop and saving it in object \"sentence_\"\n",
    "# line 33 : generating new sentences by replacing words with their synonyms , \n",
    "# here \"n_\" is the number of new texts we want to generate for the given text , ( 1852 - 917 ) // 917 , this value\n",
    "# num_threads is number of cores to use\n",
    "# line 35 to 39 : appending each of total generated texts with respective classes to lists texts_ and labels_\n",
    "# lastly printing the total time taken for the process\n",
    "\n",
    "for i in df.Domain.value_counts().index.values[1:]:\n",
    "    n_ = round((1852 - len(df[df['Domain']==i]))/len(df[df['Domain']==i]))\n",
    "    print(n_ , len(df[df['Domain']==i]))\n",
    "\n",
    "    for j in tqdm(range(len(df[df['Domain']==i]))):\n",
    "        sentence_ = df[df['Domain']==i].iloc[j,1]\n",
    "        aug_texts = augmenter.augment(sentence_ , n = n_,num_thread=multiprocessing.cpu_count())\n",
    "        \n",
    "        for k in aug_texts:\n",
    "            texts_.append(k)\n",
    "            labels_.append(df[df['Domain']==i].iloc[j,2])\n",
    "            \n",
    "print(\"total time taken to complete is : \",(time.time() - start_)/60 ,\" minutes .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a321956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above process we have created the newly genrated texts , now we combine the original and new genrated texts.\n",
    "\n",
    "texts_ = texts_ + df.Title.tolist()\n",
    "labels_ = labels_ + df.Domain.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ad45c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataset\n",
    "df_new = pd.DataFrame({\"Title\" : texts_ , \"Domain\" : labels_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e314e4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plot on Google Map in Python</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R code throws the computer error Error in run ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to do grouping by in Roentgen</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to take records containing sure name in th...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deterrent example of XGBoost utilise Julia on ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Domain\n",
       "0                       Plot on Google Map in Python       6\n",
       "1  R code throws the computer error Error in run ...       6\n",
       "2                  How to do grouping by in Roentgen       6\n",
       "3  How to take records containing sure name in th...       6\n",
       "4  Deterrent example of XGBoost utilise Julia on ...       6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd3f9236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Domain\n",
       "4    1870\n",
       "5    1852\n",
       "2    1850\n",
       "6    1834\n",
       "1    1834\n",
       "3    1830\n",
       "0    1748\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"Domain\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f87eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the balanced datafrme , so that the process can be resumed from her ewithout executing the above lines again and again\n",
    "df_new.to_csv(\"df_naw.SynonymAug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2891c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved csv\n",
    "df_new = pd.read_csv(\"df_ContextualWordEmbsAug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81677b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f12129f",
   "metadata": {},
   "source": [
    "# tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85edf44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the  texts into vector uing tfidf\n",
    "# calculating the similarities among vectors using linear kernel\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tf\n",
    "tf_ = tf(stop_words='english')\n",
    "tf_.fit(df_new['Title'])\n",
    "x = tf_.transform(df_new[\"Title\"])\n",
    "x = linear_kernel(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66bf151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12818, 12818)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17cce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,df_new['Domain'] ,test_size = 0.3 , random_state = 12345 , stratify = df_new['Domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97878b",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb0e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the problem said the f1_Score with average as \"macro\" should be used as metric for auuracy\n",
    "# f1_score can be directly used  like we use sklearn.metric.acuracy\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6973e1",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230cce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "# use all cores while training so that the process is done fast using all cores\n",
    "os.environ['OMP_NUM_THREADS'] = str(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bfa29bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=123)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVC(random_state=123)\n",
    "svm_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "02c2d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4fa74aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717606803215249\n"
     ]
    }
   ],
   "source": [
    "# printing the f1_score on training and testing set\n",
    "print(f1_score(y_test,y_pred,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae37b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_train,svm_model.predict(x_train),average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532d594",
   "metadata": {},
   "source": [
    "# classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da213420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report as cr\n",
    "\n",
    "print(cr(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4454e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2509a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b6f72aa",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8b7c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier as sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aa8679bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [0.76, 0.70, 0.77, 0.70, 0.69, 0.55, 0.61]\n",
    "class_weights = {i: 1/f1_scores[i] for i in range(len(f1_scores))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "34531516",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_ = sgd(random_state = 123 , alpha= 0.0001, loss = 'hinge',penalty = 'l2',class_weight = class_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67fe5e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(class_weight={0: 1.3157894736842106, 1: 1.4285714285714286,\n",
       "                            2: 1.2987012987012987, 3: 1.4285714285714286,\n",
       "                            4: 1.4492753623188408, 5: 1.8181818181818181,\n",
       "                            6: 1.639344262295082},\n",
       "              random_state=123)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc862a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd_.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dbc9446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707148261237497\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test,y_pred,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a963b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046794941290066\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train,sgd_.predict(x_train),average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "709f4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       525\n",
      "           1       0.73      0.67      0.70       550\n",
      "           2       0.75      0.80      0.77       555\n",
      "           3       0.68      0.72      0.70       549\n",
      "           4       0.67      0.72      0.69       561\n",
      "           5       0.56      0.53      0.55       556\n",
      "           6       0.64      0.57      0.61       550\n",
      "\n",
      "    accuracy                           0.68      3846\n",
      "   macro avg       0.68      0.68      0.68      3846\n",
      "weighted avg       0.68      0.68      0.68      3846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report\n",
    "print(cr(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0900bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb80d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5af9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c491b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f13d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504cfb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d2d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "636e836e",
   "metadata": {},
   "source": [
    "# below are the f1_Scores for each model for test and train data with different parameters , # first test accuracy , second train accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad17342",
   "metadata": {},
   "source": [
    "### SGD_ = SGD(random_state = 123 , 'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l2') # 85 , 95\n",
    "\n",
    "### svm_model_ = svm.svc({'C': 1.0,'break_ties': False, 'cache_size': 200,'class_weight': None,'coef0': 0.0,'decision_function_shape': 'ovr','degree': 3,'gamma': 'scale','kernel': 'rbf','max_iter': -1,'probability': False,'random_state': 123,'shrinking': True,'tol': 0.001,'verbose': False}) # 85 , 94\n",
    "\n",
    "### svm_model = svm.SVC(random_state=123 ,C = 1 , kernel = 'rbf' , gamma = \"scale\") # 85 , 94\n",
    "\n",
    "### svm_model = svm.SVC(random_state=123 ,C = 3 , kernel = 'rbf' , gamma = \"scale\")# 89 , 99\n",
    "\n",
    "### svm_model = svm.SVC(random_state=123 ,C = 1 , kernel = 'linear' , gamma = \"scale\") # 86 , 97\n",
    "\n",
    "### svm_model = svm.SVC(random_state=123 ,C = 2 , kernel = 'rbf' , gamma = \"scale\") # 88 , 98\n",
    "\n",
    "### svm_model = svm.SVC(random_state=123 ,C = 1 , kernel = 'linear' , gamma = \"auto\") # 86 , 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd6d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4cc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50d2770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "403123de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB ,MultinomialNB,BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier , ExtraTreesClassifier , BaggingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score , confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69aecbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.ensemble import GradientBoostingClassifier'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
    "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
    "xgb = XGBClassifier(n_estimators=50,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b3a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not including svm as its taking long time\n",
    "clfs = {'KN' : knc, 'NB': mnb,'DT': dtc, 'LR': lrc, 'RF': rfc, 'AdaBoost': abc, 'Bc': bc, 'ETC': etc,'GBDT':gbdt,'xgb':xgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e6bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,x_train,y_train,x_test,y_test):\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    f1_train = f1_score(y_train,clf.predict(x_train),average=\"macro\")\n",
    "\n",
    "    f1_test = f1_score(y_test,y_pred,average=\"macro\")\n",
    "    \n",
    "    return f1_train , f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01a350d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  KN\n",
      "      f1_train  0.7622894024233281\n",
      "      f1_test  0.6090990059314189\n",
      "For  NB\n",
      "      f1_train  0.5432953519264271\n",
      "      f1_test  0.49577874867397387\n",
      "For  DT\n",
      "      f1_train  0.25111662582019095\n",
      "      f1_test  0.22985122905544877\n",
      "For  LR\n",
      "      f1_train  0.7802037487032454\n",
      "      f1_test  0.6724910976667895\n",
      "For  RF\n",
      "      f1_train  0.9958935649317998\n",
      "      f1_test  0.6584792972739143\n",
      "For  AdaBoost\n",
      "      f1_train  0.40985622755728146\n",
      "      f1_test  0.3782498220517271\n",
      "For  Bc\n",
      "      f1_train  0.9956662457630471\n",
      "      f1_test  0.673482027658529\n",
      "For  ETC\n",
      "      f1_train  0.9960101038856762\n",
      "      f1_test  0.6744502291309085\n",
      "For  GBDT\n",
      "      f1_train  0.7162186575849857\n",
      "      f1_test  0.5749875571499595\n",
      "For  xgb\n",
      "      f1_train  0.9065630886817486\n",
      "      f1_test  0.6711409847791895\n",
      "total time taken to complete training fo all models is  : 200.27084197600684\n"
     ]
    }
   ],
   "source": [
    "# promoted is 1 and not promoted is 0\n",
    "# we are considering recall in this case because we may have two models with same f1-score \n",
    "# then we will select the one with better recall\n",
    "# this is beacuse we dont want our model predict an employee as not promoted to an employee who is actually promoted .\n",
    "# this will bring down the morale of loyal and hardworking employees\n",
    "# the more that happens the more goes down the morale of hard working a loyal employees .\n",
    "\n",
    "time.sleep(1)\n",
    "start_ = time.time()\n",
    "\n",
    "f1_scores_train = []\n",
    "recall_scores_train = []\n",
    "f1_scores_test = []\n",
    "recall_scores_test = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    f1_train , f1_test= train_classifier(clf, x_train,y_train,x_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"      f1_train \",f1_train)\n",
    "    print(\"      f1_test \",f1_test)\n",
    "\n",
    "    f1_scores_train.append(f1_train)\n",
    "    f1_scores_test.append(f1_test)\n",
    "\n",
    "    \n",
    "print(f\"total time taken to complete training fo all models is  : {(time.time()-start_)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecb75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffcb9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the performance considering region variable\n",
    "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'f1_train':f1_scores_train,'f1_test':f1_scores_test}).sort_values('f1_test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c614d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ETC</td>\n",
       "      <td>0.996010</td>\n",
       "      <td>0.674450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bc</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>0.673482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.780204</td>\n",
       "      <td>0.672491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.906563</td>\n",
       "      <td>0.671141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.995894</td>\n",
       "      <td>0.658479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KN</td>\n",
       "      <td>0.762289</td>\n",
       "      <td>0.609099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.716219</td>\n",
       "      <td>0.574988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.543295</td>\n",
       "      <td>0.495779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>0.378250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.251117</td>\n",
       "      <td>0.229851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  f1_train   f1_test\n",
       "7       ETC  0.996010  0.674450\n",
       "6        Bc  0.995666  0.673482\n",
       "3        LR  0.780204  0.672491\n",
       "9       xgb  0.906563  0.671141\n",
       "4        RF  0.995894  0.658479\n",
       "0        KN  0.762289  0.609099\n",
       "8      GBDT  0.716219  0.574988\n",
       "1        NB  0.543295  0.495779\n",
       "5  AdaBoost  0.409856  0.378250\n",
       "2        DT  0.251117  0.229851"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8331ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951010e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "068bdf71",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd092029",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SGD_ = SGDClassifier(random_state=123, alpha=0.0001, loss='hinge', penalty='l2')\n",
    "svm_model = SVC(random_state=123 ,C = 2 , kernel = 'rbf' , gamma = \"scale\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9df1eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying stacking\n",
    "estimators=[('sgd_', SGD_), ('svm',svm_model)]\n",
    "final_estimator= SVC(random_state=123 ,C = 2 , kernel = 'rbf' , gamma = \"scale\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd689a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c14dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae84e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03c7a399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_train 0.9529914285710743\n",
      "f1_test 0.7442564295696775\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_train\",f1_score(clf.predict(x_train),y_train,average='macro'))\n",
    "print(\"f1_test\",f1_score(y_test,y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924bec41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4de347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca796ee7",
   "metadata": {},
   "source": [
    "# voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "SGD_ = SGDClassifier(random_state=123, alpha=0.0001, loss='hinge', penalty='l2')\n",
    "svm_model = SVC(random_state=123 ,C = 2 , kernel = 'rbf' , gamma = \"scale\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[('sgd_', SGD_), ('svm',svm_model)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cdad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(x_train,y_train)\n",
    "y_pred = voting.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d33b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f1_train\",f1_score(voting.predict(x_train),y_train))\n",
    "print(\"f1_test\",f1_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
